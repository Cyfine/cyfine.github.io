<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>ICML on Carter&#39;s Blog</title>
    <link>https://cyfine.github.io/tags/icml/</link>
    <description>Recent content in ICML on Carter&#39;s Blog</description>
    <image>
      <url>https://cyfine.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</url>
      <link>https://cyfine.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Tue, 02 Aug 2022 11:31:28 +0800</lastBuildDate><atom:link href="https://cyfine.github.io/tags/icml/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Pac Net a Model Pruning  Approach</title>
      <link>https://cyfine.github.io/posts/pac-net-a-model-pruning-approach/</link>
      <pubDate>Tue, 02 Aug 2022 11:31:28 +0800</pubDate>
      
      <guid>https://cyfine.github.io/posts/pac-net-a-model-pruning-approach/</guid>
      <description>1. Abstract When using over-parameterized model, the author found the model can be pruned without losing most of the accuracy.
The author identifies the essential weight using LWM to obtain mask. For pruned model, train on source domain with regularization. Then, transfer the model on the target domain, freeze un-pruned parameter on the source domain, train only the parameter being pruned on the target domain. 2. Contribution Very first using pruning in transfer learning.</description>
    </item>
    
  </channel>
</rss>
